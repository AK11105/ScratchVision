# Object Detection Learning Timeline (PyTorch Focused)

This roadmap outlines the evolution of **object detection** architectures â€” from sliding windows and region-based detectors to transformer-based models â€” highlighting which to **read**, **partially implement**, or **fully implement** for a practical PyTorch learning path.

---

## 1ï¸âƒ£ Early & Foundational Detectors

### ğŸ§  **R-CNN (2014)** â€“ âš™ï¸ğŸ“– *Partial Implementation*

* **Key Innovation**: Combined selective search (region proposals) with CNN feature extraction and SVM classification.
* **Learning Focus**: Understand region proposals + CNN-based classification pipeline.
* **Paper**: [Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation](https://arxiv.org/abs/1311.2524)

---

### ğŸ§  **Fast R-CNN (2015)** â€“ âš™ï¸ *Must Implement*

* **Key Innovation**: Shared CNN feature maps + ROI pooling for faster detection.
* **Learning Focus**: Implement ROI pooling and shared backbone.
* **Paper**: [Fast R-CNN](https://arxiv.org/abs/1504.08083)

---

### ğŸ§  **Faster R-CNN (2015)** â€“ âš™ï¸ *Must Implement*

* **Key Innovation**: Introduced the Region Proposal Network (RPN).
* **Learning Focus**: Implement RPN, anchors, and end-to-end training.
* **Paper**: [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497)

---

## 2ï¸âƒ£ Single-Stage Detectors (Speed-Oriented)

### ğŸ§  **YOLO v1 (2016)** â€“ âš™ï¸ *Must Implement*

* **Key Innovation**: Replaced proposals with direct bounding box regression.
* **Learning Focus**: Grid-based detection and bounding box parameterization.
* **Paper**: [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)

---

### ğŸ§  **SSD (2016)** â€“ âš™ï¸ğŸ“– *Partial Implementation*

* **Key Innovation**: Multi-scale feature maps for detecting different object sizes.
* **Learning Focus**: Feature pyramid concept and anchor-based detection.
* **Paper**: [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325)

---

### ğŸ§  **YOLOv2 / YOLO9000 (2017)** â€“ ğŸ“– *Read Only*

* **Key Innovation**: Introduced batch norm, anchor boxes, and multi-scale training.
* **Learning Focus**: Learn improvements over YOLOv1.
* **Paper**: [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242)

---

### ğŸ§  **RetinaNet (2017)** â€“ âš™ï¸ğŸ“– *Partial Implementation*

* **Key Innovation**: Introduced **Focal Loss** to handle class imbalance.
* **Learning Focus**: Implement Focal Loss and understand one-stage vs two-stage trade-offs.
* **Paper**: [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)

---

## 3ï¸âƒ£ Modern Object Detectors

### ğŸ§  **YOLOv3 (2018)** â€“ âš™ï¸ğŸ“– *Partial Implementation*

* **Key Innovation**: Multi-scale prediction, residual backbones (Darknet-53).
* **Learning Focus**: Explore detection across different scales and feature maps.
* **Paper**: [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767)

---

### ğŸ§  **YOLOv5 (2020)** â€“ âš™ï¸ *Implement Using Codebase*

* **Key Innovation**: PyTorch-native, modern training pipelines, anchors, augmentation.
* **Learning Focus**: Use pretrained models, fine-tune, and visualize training.
* **Repo**: [ultralytics/yolov5](https://github.com/ultralytics/yolov5)

---

### ğŸ§  **EfficientDet (2020)** â€“ âš™ï¸ğŸ“– *Partial Implementation*

* **Key Innovation**: Compound scaling + BiFPN for efficient feature fusion.
* **Learning Focus**: Implement BiFPN block and scaling rules.
* **Paper**: [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070)

---

### ğŸ§  **DETR (2020)** â€“ âš™ï¸ *Must Implement (Simplified)*

* **Key Innovation**: Transformer-based detection removing need for anchors/NMS.
* **Learning Focus**: Implement a minimal DETR with transformer encoder-decoder.
* **Paper**: [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)

---

### ğŸ§  **YOLOv8 (2023)** â€“ ğŸ“– *Read Only*

* **Key Innovation**: Anchor-free design + hybrid backbone.
* **Learning Focus**: Understand current state-of-the-art anchor-free trends.
* **Repo**: [ultralytics/YOLOv8](https://github.com/ultralytics/ultralytics)

---

## ğŸ§­ Implementation Path (PyTorch Order)

| Phase                      | Focus                           | What to Implement         | Key Concepts                  |
| -------------------------- | ------------------------------- | ------------------------- | ----------------------------- |
| **1ï¸âƒ£ Early Two-Stage**    | Learn proposal-based detection  | Fast R-CNN â†’ Faster R-CNN | ROI pooling, RPN, anchors     |
| **2ï¸âƒ£ One-Stage Models**   | Learn speed-optimized detection | YOLOv1 â†’ RetinaNet        | Anchor boxes, Focal Loss      |
| **3ï¸âƒ£ Transformer Models** | Learn end-to-end detection      | DETR                      | Attention, NMS-free detection |
| **4ï¸âƒ£ Modern Practice**    | Apply pretrained models         | YOLOv5 / YOLOv8           | Training, deployment, metrics |

---

## âœ… Summary

* **Must Implement**: Fast R-CNN, Faster R-CNN, YOLOv1, DETR
* **Partial Implementation**: SSD, RetinaNet, YOLOv3, EfficientDet
* **Read Only**: YOLOv2, YOLOv8

